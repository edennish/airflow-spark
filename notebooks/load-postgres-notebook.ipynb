{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/12/29 16:06:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark session & context\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master(\"local\")\n",
    "         .appName(\"load-postgres\")\n",
    "         # Add postgres jar\n",
    "         #.config(\"spark.driver.extraClassPath\", \"/home/jovyan/work/jars/postgresql-9.4.1207.jar\")\n",
    "         .config(\"spark.driver.extraClassPath\", \"/usr/local/spark/resources/jars/postgresql-9.4.1207.jar\")\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_csv = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .load(\"/home/jovyan/work/data/movies.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_csv = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .load(\"/home/jovyan/work/data/ratings.csv\")\n",
    "    .withColumnRenamed(\"timestamp\",\"timestamp_epoch\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert epoch to timestamp and rating to DoubleType\n",
    "from pyspark.sql.functions import from_unixtime, col, to_timestamp\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "df_ratings_csv_fmt = (\n",
    "    df_ratings_csv\n",
    "    .withColumn('rating', col(\"rating\").cast(DoubleType()))\n",
    "    .withColumn('timestamp', to_timestamp(from_unixtime(col(\"timestamp_epoch\"))))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_movies_csv.write\n",
    " .format(\"jdbc\")\n",
    " .option(\"url\", \"jdbc:postgresql://postgres/test\")\n",
    " .option(\"dbtable\", \"public.movies\")\n",
    " .option(\"user\", \"test\")\n",
    " .option(\"password\", \"postgres\")\n",
    " .mode(\"overwrite\")\n",
    " .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df_ratings_csv_fmt\n",
    " .select([c for c in df_ratings_csv_fmt.columns if c != \"timestamp_epoch\"])\n",
    " .write\n",
    " .format(\"jdbc\")\n",
    " .option(\"url\", \"jdbc:postgresql://postgres/test\")\n",
    " .option(\"dbtable\", \"public.ratings\")\n",
    " .option(\"user\", \"test\")\n",
    " .option(\"password\", \"postgres\")\n",
    " .mode(\"overwrite\")\n",
    " .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId movieId rating timestamp_epoch\n",
       "0      1       1    4.0       964982703\n",
       "1      1       3    4.0       964981247\n",
       "2      1       6    4.0       964982224\n",
       "3      1      47    5.0       964983815\n",
       "4      1      50    5.0       964982931\n",
       "5      1      70    3.0       964982400\n",
       "6      1     101    5.0       964980868\n",
       "7      1     110    4.0       964982176\n",
       "8      1     151    5.0       964984041\n",
       "9      1     157    5.0       964984100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings_csv.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = (\n",
    "    spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"url\", \"jdbc:postgresql://postgres/airflow\")\n",
    "    .option(\"dbtable\", \"public.dag\")\n",
    " .option(\"user\", \"airflow\")\n",
    " .option(\"password\", \"airflow\")\n",
    "    .load() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dag_id</th>\n",
       "      <th>is_paused</th>\n",
       "      <th>is_subdag</th>\n",
       "      <th>is_active</th>\n",
       "      <th>last_scheduler_run</th>\n",
       "      <th>last_pickled</th>\n",
       "      <th>last_expired</th>\n",
       "      <th>scheduler_lock</th>\n",
       "      <th>pickle_id</th>\n",
       "      <th>fileloc</th>\n",
       "      <th>owners</th>\n",
       "      <th>description</th>\n",
       "      <th>default_view</th>\n",
       "      <th>schedule_interval</th>\n",
       "      <th>root_dag_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spark-hello-world-module</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-12-29 16:06:21.480572</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/usr/local/airflow/dags/spark-hello-world-modu...</td>\n",
       "      <td>airflow</td>\n",
       "      <td>This DAG runs a Pyspark app that uses modules.</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"type\": \"timedelta\", \"attrs\": {\"days\": 1, \"se...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spark-test</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-12-29 16:06:22.482156</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/usr/local/airflow/dags/spark-test.py</td>\n",
       "      <td>airflow</td>\n",
       "      <td>This DAG runs a simple Pyspark app.</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"type\": \"timedelta\", \"attrs\": {\"days\": 1, \"se...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spark-postgres</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-12-29 16:06:22.492430</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/usr/local/airflow/dags/spark-postgres.py</td>\n",
       "      <td>airflow</td>\n",
       "      <td>This DAG is a sample of integration between Sp...</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"type\": \"timedelta\", \"attrs\": {\"days\": 1, \"se...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dag_id  is_paused  is_subdag  is_active  \\\n",
       "0  spark-hello-world-module       True      False       True   \n",
       "1                spark-test       True      False       True   \n",
       "2            spark-postgres       True      False       True   \n",
       "\n",
       "          last_scheduler_run last_pickled last_expired scheduler_lock  \\\n",
       "0 2021-12-29 16:06:21.480572          NaT          NaT           None   \n",
       "1 2021-12-29 16:06:22.482156          NaT          NaT           None   \n",
       "2 2021-12-29 16:06:22.492430          NaT          NaT           None   \n",
       "\n",
       "   pickle_id                                            fileloc   owners  \\\n",
       "0        NaN  /usr/local/airflow/dags/spark-hello-world-modu...  airflow   \n",
       "1        NaN              /usr/local/airflow/dags/spark-test.py  airflow   \n",
       "2        NaN          /usr/local/airflow/dags/spark-postgres.py  airflow   \n",
       "\n",
       "                                         description default_view  \\\n",
       "0     This DAG runs a Pyspark app that uses modules.         None   \n",
       "1                This DAG runs a simple Pyspark app.         None   \n",
       "2  This DAG is a sample of integration between Sp...         None   \n",
       "\n",
       "                                   schedule_interval root_dag_id  \n",
       "0  {\"type\": \"timedelta\", \"attrs\": {\"days\": 1, \"se...        None  \n",
       "1  {\"type\": \"timedelta\", \"attrs\": {\"days\": 1, \"se...        None  \n",
       "2  {\"type\": \"timedelta\", \"attrs\": {\"days\": 1, \"se...        None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
